{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "mus=[0.001, 0.05, 0.1, 0.5, 0.98]\n",
    "thetas=[math.pi/90, math.pi/6,math.pi/4,math.pi/3,math.pi*44/45]\n",
    "g=9.8\n",
    "masses=[0.5, 1, 2, 5, 100, 7]\n",
    "u0s=[0.1, 0, 0.5, 2, 0.9]\n",
    "v0s=[0, 0.01, 0.9, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=np.load('data/loc_test_springs5.npy')\n",
    "vel=np.load('data/vel_test_springs5.npy')\n",
    "edge=np.load('data/edges_test_springs5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 2, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc.shape #10 trials, each 10 length, x y axis, about 5 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[num_sims, num_atoms, num_timesteps, num_dims] 5x5x5x5,5,4,1\n",
    "step=19\n",
    "interval=2\n",
    "data=[]\n",
    "for shape in [1,2,3]:\n",
    "    s=[[shape,1,0,0,0,0,0,0]]*step\n",
    "    for color in [40,57,213,9,254]:\n",
    "        c=[[color,0,1,0,0,0,0,0]]*step\n",
    "        for mu in mus:\n",
    "            friction = [[mu,0,0,1,0,0,0,0]]*step\n",
    "            for theta in thetas:\n",
    "                t = [[theta,0,0,0,1,0,0,0]]*step\n",
    "                for mass in masses:\n",
    "                    m = [[mass,0,0,0,0,1,0,0]]*step\n",
    "                    for u0 in u0s:\n",
    "#                         u = [u0]*step\n",
    "                        for v0 in v0s:\n",
    "#                             v = [v0]*step\n",
    "                            loc = np.zeros((step, 8))\n",
    "                            loc[0,0] = u0\n",
    "                            loc[:,1:] =[0,0,0,0,0,0,1]\n",
    "                            vel = np.zeros((step, 8))\n",
    "                            vel[0,0] = v0\n",
    "                            vel[:,1:] =[0,0,0,0,0,1,0]\n",
    "                            for i in range(1, step):\n",
    "                                loc[i, 0]=loc[i-1, 0]+vel[i-1,0]*interval+0.5*g*(np.sin(theta)-np.cos(theta)*mu)*(interval**2)\n",
    "                                vel[i, 0] = vel[i-1, 0]+g*(np.sin(theta)-np.cos(theta)*mu)\n",
    "                            #monitor the loss of vel_curr,loc_curr, \n",
    "                            #each dim 1+one_hot_semantic=9\n",
    "                            #self.rel_graph=8x8\n",
    "                            #\n",
    "                            #[s,c,friction,t,m,vel_curr,loc_curr], [s,c,friction,t,m, [loc_prevs]]\n",
    "                            trial=np.stack([s,c,friction,t,m,vel,loc],axis=0) \n",
    "                            data.append(trial)\n",
    "                            \n",
    "                          \n",
    "                            \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[num_sims, num_atoms, num_timesteps, num_dims] 5x5x5x5,5,4,1\n",
    "step=19\n",
    "interval=2\n",
    "data=[]\n",
    "for shape in [1,2,3]:\n",
    "    s=[shape]*step\n",
    "    for color in [40,57,213,9,254]:\n",
    "        c=[color]*step\n",
    "        for mu in mus:\n",
    "            friction = [mu]*step\n",
    "            for theta in thetas:\n",
    "                t = [theta]*step\n",
    "                for mass in masses:\n",
    "                    m = [mass]*step\n",
    "                    for u0 in u0s:\n",
    "#                         u = [u0]*step\n",
    "                        for v0 in v0s:\n",
    "#                             v = [v0]*step\n",
    "                            loc = np.zeros(step)\n",
    "                            loc[0] = u0\n",
    "#                             loc[:,1:] =[0,0,0,0,0,0,1]\n",
    "                            vel = np.zeros(step)\n",
    "                            vel[0] = v0\n",
    "#                             vel[:,1:] =[0,0,0,0,0,1,0]\n",
    "                            for i in range(1, step):\n",
    "                                loc[i]=loc[i-1]+vel[i-1]*interval+0.5*g*(np.sin(theta)-np.cos(theta)*mu)*(interval**2)\n",
    "                                vel[i] = vel[i-1]+g*(np.sin(theta)-np.cos(theta)*mu)\n",
    "                            #monitor the loss of vel_curr,loc_curr, \n",
    "                            #each dim 1+one_hot_semantic=9\n",
    "                            #self.rel_graph=8x8\n",
    "                            #\n",
    "                            #[s,c,friction,t,m,vel_curr,loc_curr], [s,c,friction,t,m, [loc_prevs]]\n",
    "                            trial=np.stack([s,c,friction,t,m,vel,loc],axis=0) \n",
    "                            data.append(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56250, 7, 19, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data=np.expand_dims(np.array(data),-1)\n",
    "# data_new=np.array(data)\n",
    "new_data.shape\n",
    "data_new=new_data\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [4.00000000e+01],\n",
       "       [1.00000000e-03],\n",
       "       [3.49065850e-02],\n",
       "       [5.00000000e-01],\n",
       "       [6.64442075e-01],\n",
       "       [2.09332623e+00]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new[0,:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56250, 7, 7)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge=np.array([[0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,0]])  \n",
    "edge=np.array([[0,0,0,0,0,0,0],\\\n",
    "               [0,0,0,0,0,0,0],\\\n",
    "               [0,0,0,0,0,0,1],\\\n",
    "               [0,0,0,0,0,0,1],\\\n",
    "               [0,0,0,0,0,0,0],\\\n",
    "               [0,0,0,0,0,0,1],\\\n",
    "               [0,0,0,0,0,0,0]]) \n",
    "edge=np.repeat(np.expand_dims(edge,0),data_new.shape[0],axis=0)\n",
    "edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24230 38042  3469 44215 19277 29376 37987 55167 17192 20077]\n"
     ]
    }
   ],
   "source": [
    "arr=np.arange(56250)\n",
    "np.random.shuffle(arr)\n",
    "print(arr[:10])\n",
    "np.save('data/feat_train_causal_vel_nohot.npy',data_new[arr[:45000]])\n",
    "np.save('data/feat_valid_causal_vel_nohot.npy',data_new[arr[45000:50000]])\n",
    "np.save('data/feat_test_causal_vel_nohot.npy',data_new[arr[50000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/edges_train_causal_vel_nohot.npy',edge[:45000])\n",
    "np.save('data/edges_valid_causal_vel_nohot.npy',edge[45000:50000])\n",
    "np.save('data/edges_test_causal_vel_nohot.npy',edge[50000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.zeros_like(data)\n",
    "for i in range(0, data.shape[1]):\n",
    "        new_data[:,i,:,:] = (data[:,i,:,:] - np.min(data[:,i,:,:]))*2/(np.max(data[:,i,:,:])-np.min(data[:,i,:,:]))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(new_data[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = np.squeeze(np.load('logs/exp2020-06-27T06:41:05.204948/100_rel_graph_grad.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 56, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " debug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4561, 0.5439],\n",
       "        [0.4784, 0.5216],\n",
       "        [0.4419, 0.5581],\n",
       "        [0.5065, 0.4935],\n",
       "        [0.5450, 0.4550],\n",
       "        [0.4704, 0.5296],\n",
       "        [0.4956, 0.5044],\n",
       "        [0.4326, 0.5674],\n",
       "        [0.4694, 0.5306],\n",
       "        [0.5221, 0.4779],\n",
       "        [0.5498, 0.4502],\n",
       "        [0.4617, 0.5383],\n",
       "        [0.5222, 0.4778],\n",
       "        [0.5739, 0.4261],\n",
       "        [0.5347, 0.4653],\n",
       "        [0.4973, 0.5027],\n",
       "        [0.4888, 0.5112],\n",
       "        [0.5077, 0.4923],\n",
       "        [0.4504, 0.5496],\n",
       "        [0.5579, 0.4421],\n",
       "        [0.5229, 0.4771],\n",
       "        [0.5078, 0.4922],\n",
       "        [0.5242, 0.4758],\n",
       "        [0.4749, 0.5251],\n",
       "        [0.5070, 0.4930],\n",
       "        [0.4725, 0.5275],\n",
       "        [0.5110, 0.4890],\n",
       "        [0.5580, 0.4420],\n",
       "        [0.5095, 0.4905],\n",
       "        [0.5257, 0.4743],\n",
       "        [0.5509, 0.4491],\n",
       "        [0.5185, 0.4815],\n",
       "        [0.5544, 0.4456],\n",
       "        [0.5458, 0.4542],\n",
       "        [0.4814, 0.5186],\n",
       "        [0.4988, 0.5012],\n",
       "        [0.4573, 0.5427],\n",
       "        [0.4657, 0.5343],\n",
       "        [0.4529, 0.5471],\n",
       "        [0.4738, 0.5262],\n",
       "        [0.5055, 0.4945],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.5020, 0.4980],\n",
       "        [0.4962, 0.5038],\n",
       "        [0.5431, 0.4569],\n",
       "        [0.4895, 0.5105],\n",
       "        [0.4838, 0.5162],\n",
       "        [0.4997, 0.5003],\n",
       "        [0.5111, 0.4889],\n",
       "        [0.5454, 0.4546],\n",
       "        [0.4634, 0.5366],\n",
       "        [0.5051, 0.4949],\n",
       "        [0.5337, 0.4663],\n",
       "        [0.4759, 0.5241],\n",
       "        [0.4905, 0.5095],\n",
       "        [0.5431, 0.4569]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T06:41:05.204948/0_rel_graph.npy'))[0]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.squeeze(np.load('logs/exp2020-06-27T06:41:05.204948/10_rel_graph.npy'))[0]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6],\n",
       "        [ 7],\n",
       "        [20],\n",
       "        [49],\n",
       "        [50],\n",
       "        [51],\n",
       "        [52],\n",
       "        [53],\n",
       "        [54],\n",
       "        [55]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt: 20,27,41,48\n",
    "torch.nonzero(F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T19:11:06.878733/20_rel_graph.npy'))[0]),dim=1).argmax(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7402, 0.2598],\n",
       "        [0.7477, 0.2523],\n",
       "        [0.7370, 0.2630],\n",
       "        [0.7531, 0.2469],\n",
       "        [0.7642, 0.2358],\n",
       "        [0.7428, 0.2572],\n",
       "        [0.7183, 0.2817],\n",
       "        [0.6943, 0.3057],\n",
       "        [0.7546, 0.2454],\n",
       "        [0.7804, 0.2196],\n",
       "        [0.7771, 0.2229],\n",
       "        [0.7500, 0.2500],\n",
       "        [0.7788, 0.2212],\n",
       "        [0.7915, 0.2085],\n",
       "        [0.7376, 0.2624],\n",
       "        [0.7285, 0.2715],\n",
       "        [0.7316, 0.2684],\n",
       "        [0.7282, 0.2718],\n",
       "        [0.7312, 0.2688],\n",
       "        [0.7713, 0.2287],\n",
       "        [0.7114, 0.2886],\n",
       "        [0.7461, 0.2539],\n",
       "        [0.7513, 0.2487],\n",
       "        [0.7420, 0.2580],\n",
       "        [0.7439, 0.2561],\n",
       "        [0.7412, 0.2588],\n",
       "        [0.7507, 0.2493],\n",
       "        [0.7540, 0.2460],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7010, 0.2990],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7011, 0.2989],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7005, 0.2995],\n",
       "        [0.7259, 0.2741],\n",
       "        [0.7280, 0.2720],\n",
       "        [0.7234, 0.2766],\n",
       "        [0.7309, 0.2691],\n",
       "        [0.7267, 0.2733],\n",
       "        [0.7332, 0.2668],\n",
       "        [0.7195, 0.2805],\n",
       "        [0.7166, 0.2834],\n",
       "        [0.7147, 0.2853],\n",
       "        [0.7166, 0.2834],\n",
       "        [0.7146, 0.2854],\n",
       "        [0.7158, 0.2842],\n",
       "        [0.7159, 0.2841],\n",
       "        [0.7057, 0.2943],\n",
       "        [0.3017, 0.6983],\n",
       "        [0.2164, 0.7836],\n",
       "        [0.2134, 0.7866],\n",
       "        [0.1982, 0.8018],\n",
       "        [0.2129, 0.7871],\n",
       "        [0.2459, 0.7541],\n",
       "        [0.2430, 0.7570]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T18:33:05.207373/150_rel_graph.npy'))[0]),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3916e-02, -2.3916e-02],\n",
       "        [ 4.6865e-02, -4.6865e-02],\n",
       "        [ 2.3737e-03, -2.3737e-03],\n",
       "        [ 5.2621e-04, -5.2621e-04],\n",
       "        [ 4.8675e-03, -4.8675e-03],\n",
       "        [ 2.5948e-02, -2.5948e-02],\n",
       "        [ 2.2249e-02, -2.2249e-02],\n",
       "        [-6.3811e-03,  6.3811e-03],\n",
       "        [-1.6867e-02,  1.6867e-02],\n",
       "        [-1.5393e-05,  1.5393e-05],\n",
       "        [-1.2491e-04,  1.2491e-04],\n",
       "        [-1.4796e-02,  1.4796e-02],\n",
       "        [-2.1448e-04,  2.1448e-04],\n",
       "        [-3.7762e-02,  3.7762e-02],\n",
       "        [-6.6433e-02,  6.6433e-02],\n",
       "        [-1.5416e-02,  1.5416e-02],\n",
       "        [-6.8907e-02,  6.8907e-02],\n",
       "        [-2.8558e-02,  2.8558e-02],\n",
       "        [-4.3664e-02,  4.3664e-02],\n",
       "        [-2.3036e-04,  2.3036e-04],\n",
       "        [-9.6356e-02,  9.6356e-02],\n",
       "        [-2.9030e-02,  2.9030e-02],\n",
       "        [-1.7885e-02,  1.7885e-02],\n",
       "        [-3.3899e-02,  3.3899e-02],\n",
       "        [-2.9378e-02,  2.9378e-02],\n",
       "        [-2.8083e-02,  2.8083e-02],\n",
       "        [-2.0533e-02,  2.0533e-02],\n",
       "        [-1.2789e-03,  1.2789e-03],\n",
       "        [-3.8094e-03,  3.8094e-03],\n",
       "        [-8.5271e-03,  8.5271e-03],\n",
       "        [-2.7183e-03,  2.7183e-03],\n",
       "        [-1.4224e-02,  1.4224e-02],\n",
       "        [-2.0973e-03,  2.0973e-03],\n",
       "        [-7.8611e-05,  7.8614e-05],\n",
       "        [-4.6543e-03,  4.6543e-03],\n",
       "        [-1.9400e+00,  1.9400e+00],\n",
       "        [-1.7349e+00,  1.7349e+00],\n",
       "        [-1.4441e-01,  1.4441e-01],\n",
       "        [-5.3339e+00,  5.3339e+00],\n",
       "        [-2.5113e+00,  2.5113e+00],\n",
       "        [-2.1138e+00,  2.1138e+00],\n",
       "        [-4.5610e-01,  4.5610e-01],\n",
       "        [-6.3432e-03,  6.3432e-03],\n",
       "        [-1.1211e-03,  1.1211e-03],\n",
       "        [-1.5246e-03,  1.5246e-03],\n",
       "        [-9.0128e-04,  9.0128e-04],\n",
       "        [-1.2785e-02,  1.2785e-02],\n",
       "        [-2.8390e-03,  2.8390e-03],\n",
       "        [-4.1784e-04,  4.1784e-04],\n",
       "        [ 9.1436e+00, -9.1436e+00],\n",
       "        [ 1.3748e+01, -1.3748e+01],\n",
       "        [ 1.2076e+01, -1.2076e+01],\n",
       "        [ 4.6654e-02, -4.6654e-02],\n",
       "        [ 5.0630e+00, -5.0630e+00],\n",
       "        [ 5.1234e+00, -5.1234e+00],\n",
       "        [ 1.7032e+00, -1.7031e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.squeeze(np.load('logs/exp2020-06-27T18:20:43.181813/0_rel_graph_grad.npy'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.Tensor([[[1,2,3],[4,5,6]]])\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.Tensor([[[1],[0]]])\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from modules_causal import *\n",
    "\n",
    "class MLPDecoder_Causal_1(nn.Module):\n",
    "    \"\"\"MLP decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,\n",
    "                 do_prob=0., skip_first=False, cuda=True, num_nodes=8, pred_steps=1):\n",
    "        super(MLPDecoder_Causal_1, self).__init__()\n",
    "        \n",
    "        #TODO: only the last col of the original adj matrix will be trained   \n",
    "        if cuda:\n",
    "            self.rel_graph = torch.zeros((1, 1, num_nodes*(num_nodes-1), edge_types), requires_grad=True, device=\"cuda\")\n",
    "#             self.zeros = torch.zeros((1, 1, (num_nodes-1)**2, edge_types), requires_grad=False, device=\"cuda\")\n",
    "#             self.all = torch.cat((self.zeros,self.rel_graph),dim=2)\n",
    "        else:\n",
    "            self.rel_graph = torch.zeros((1, 1, num_nodes*(num_nodes-1), edge_types), requires_grad=True)\n",
    "#         import pdb;pdb.set_trace()\n",
    "        \n",
    "        nn.init.xavier_normal_(self.rel_graph)\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_types = edge_types\n",
    "#         for i in range(0,num_nodes*(num_nodes-1)+1, num_nodes-1):\n",
    "#             self.rel_graph[:,:,i,:]=random.random()\n",
    "   \n",
    "            \n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)])\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "        #dim small to large to small\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send, \n",
    "                            single_timestep_rel_type):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        #pre_msg bs,timesteps, num_atoms*(num_atoms-1), 2\n",
    "#         print('rel_rec',rel_rec)\n",
    "#         print('rel_send', rel_send)\n",
    "\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
    "                                        pre_msg.size(2), self.msg_out_shape))\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "#         print('ffffff', single_timestep_inputs[0,0].size(), pre_msg[0,0].size())\n",
    "#         print('ffffff', single_timestep_inputs[0,0], pre_msg[0,0])\n",
    "            \n",
    "\n",
    "#         test=torch.zeros((1,1,56,1)).cuda()  51,52,54,55\n",
    "#         test[:,:,20,:]=1\n",
    "#         test[:,:,27,:]=1\n",
    "#         test[:,:,41,:]=1\n",
    "#         test[:,:,48,:]=1\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exlude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            print('start', i)\n",
    "            \n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            #single_timestep_rel_type bs, pred_steps, #node*(#node-1), #edge_type\n",
    "            #msg bs, pred_steps, #node*(#node-1), self.msg_out_shape=256\n",
    "            msg_after = msg * single_timestep_rel_type[:, :, :, i:i + 1]\n",
    "#             print('here',torch.nonzero(single_timestep_rel_type[:, :, :, i:i + 1]))\n",
    "#             msg_after = msg * self.rel_graph[:, :, :, i:i + 1]\n",
    "            all_msgs += msg_after\n",
    "            \n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        #agg_msg bs, pred_steps, #node, self.msg_out_shape=256\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        #msg bs, pred_steps, #node, self.msg_out_shape+1=257\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        #in:256, out:1\n",
    "        pred = self.out_fc3(pred)\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred, msg_after, msg\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send, tau, hard, pred_steps):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "#         logits = self.rel_graph # (inputs, rel_rec, rel_send)\n",
    "        edges = gumbel_softmax(self.rel_graph, tau, hard)\n",
    "        \n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "#         sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),\n",
    "#                  rel_type.size(2)]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "#         rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert (pred_steps <= time_steps)\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps) 5\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "\n",
    "#         curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps): \n",
    "            last_pred, all_msgs, msg = self.single_step_forward(last_pred, rel_rec, rel_send, edges)\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,\n",
    "                 preds[0].size(2), preds[0].size(3)]\n",
    "\n",
    "        output = Variable(torch.zeros(sizes))\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)): #10\n",
    "            #5 fixed points, 10 each sequence. preds[i] means the ith of each sequence.\n",
    "            output[:, i::pred_steps, :, :] = preds[i] \n",
    "        pred_all = output[:, :(inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous(), \\\n",
    "    self.rel_graph.squeeze(1).expand([inputs.size(0), self.num_nodes*(self.num_nodes-1), self.edge_types]), all_msgs, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learned interaction net decoder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = MLPDecoder_Causal_1(n_in_node=1,\n",
    "                         edge_types=2,\n",
    "                         msg_hid=256,\n",
    "                         msg_out=256,\n",
    "                         n_hid=256,\n",
    "                         do_prob=0,\n",
    "                         skip_first=True,\n",
    "                         cuda=True,\n",
    "                         num_nodes=7)\n",
    "rel_w = np.load('logs/exp2020-06-30T18:47:14.039623/0_rel_graph.npy')[-1,:,:,:]\n",
    "decoder.rel_graph = torch.Tensor(rel_w).cuda()\n",
    "decoder.load_state_dict(torch.load('logs/exp2020-06-30T18:47:14.039623/0_decoder.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = load_my_data(batch_size=128, \n",
    "                                                       suffix='_causal_vel_nohot')\n",
    "\n",
    "\n",
    "# Generate off-diagonal interaction graph, ones with only zeros on diagonal\n",
    "off_diag = np.ones([7, 7]) - np.eye(7)\n",
    "# This is not adjacency matrix since it's 56*8, not 8*8!\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1\n",
      "jjjj 0 tensor([[-0.1028, -0.0624, -0.0208,  0.0197,  0.0590,  0.0980,  0.1369,  0.1759,\n",
      "          0.2135,  0.2505,  0.2862,  0.3207,  0.3547,  0.3881,  0.4209,  0.4527,\n",
      "          0.4842,  0.5153],\n",
      "        [-0.2046, -0.2013, -0.1922, -0.1773, -0.1565, -0.1297, -0.0973, -0.0594,\n",
      "         -0.0152,  0.0338,  0.0892,  0.1494,  0.2142,  0.2847,  0.3608,  0.4406,\n",
      "          0.5191,  0.5956]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0779, -0.0555, -0.0330, -0.0106,  0.0118,  0.0342,  0.0566,  0.0791,\n",
      "          0.1015,  0.1239,  0.1463,  0.1688,  0.1912,  0.2136,  0.2360,  0.2584,\n",
      "          0.2809,  0.3033,  0.3257],\n",
      "        [-0.1004, -0.0981, -0.0935, -0.0866, -0.0774, -0.0659, -0.0521, -0.0360,\n",
      "         -0.0175,  0.0032,  0.0262,  0.0515,  0.0792,  0.1091,  0.1413,  0.1759,\n",
      "          0.2127,  0.2519,  0.2933]], device='cuda:0')\n",
      "LOSS tensor(21839.9062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 1 tensor([[-0.1015, -0.0184,  0.0621,  0.1408,  0.2191,  0.2916,  0.3625,  0.4299,\n",
      "          0.4941,  0.5563,  0.6162,  0.6748,  0.7293,  0.7815,  0.8308,  0.8778,\n",
      "          0.9235,  0.9692],\n",
      "        [-0.0995, -0.0966, -0.0885, -0.0745, -0.0546, -0.0285,  0.0032,  0.0406,\n",
      "          0.0832,  0.1312,  0.1852,  0.2421,  0.3027,  0.3674,  0.4348,  0.5067,\n",
      "          0.5813,  0.6585]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0724, -0.0340,  0.0043,  0.0426,  0.0809,  0.1192,  0.1575,  0.1958,\n",
      "          0.2342,  0.2725,  0.3108,  0.3491,  0.3874,  0.4257,  0.4640,  0.5024,\n",
      "          0.5407,  0.5790,  0.6173],\n",
      "        [-0.1004, -0.0959, -0.0875, -0.0751, -0.0588, -0.0386, -0.0144,  0.0137,\n",
      "          0.0458,  0.0817,  0.1217,  0.1655,  0.2133,  0.2650,  0.3207,  0.3802,\n",
      "          0.4438,  0.5112,  0.5826]], device='cuda:0')\n",
      "LOSS tensor(36317.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 2 tensor([[-0.0573, -0.1944, -0.3289, -0.4530, -0.5703, -0.6783, -0.7804, -0.8727,\n",
      "         -0.9568, -1.0371, -1.1165, -1.1938, -1.2686, -1.3403, -1.4091, -1.4764,\n",
      "         -1.5426, -1.6099],\n",
      "        [-0.2130, -0.2120, -0.2225, -0.2447, -0.2781, -0.3228, -0.3772, -0.4408,\n",
      "         -0.5134, -0.5931, -0.6797, -0.7715, -0.8605, -0.9495, -1.0413, -1.1361,\n",
      "         -1.2358, -1.3400]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0225, -0.0738, -0.1250, -0.1762, -0.2275, -0.2787, -0.3299, -0.3811,\n",
      "         -0.4324, -0.4836, -0.5348, -0.5861, -0.6373, -0.6885, -0.7397, -0.7910,\n",
      "         -0.8422, -0.8934, -0.9447],\n",
      "        [-0.1003, -0.0999, -0.1047, -0.1148, -0.1302, -0.1508, -0.1767, -0.2078,\n",
      "         -0.2442, -0.2859, -0.3328, -0.3850, -0.4424, -0.5051, -0.5731, -0.6463,\n",
      "         -0.7248, -0.8085, -0.8976]], device='cuda:0')\n",
      "LOSS tensor(9668.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 3 tensor([[-0.0475, -0.0389, -0.0302, -0.0216, -0.0129, -0.0043,  0.0043,  0.0129,\n",
      "          0.0214,  0.0299,  0.0385,  0.0470,  0.0554,  0.0637,  0.0720,  0.0802,\n",
      "          0.0884,  0.0966],\n",
      "        [-0.3197, -0.3009, -0.2808, -0.2594, -0.2373, -0.2140, -0.1894, -0.1637,\n",
      "         -0.1369, -0.1093, -0.0806, -0.0506, -0.0201,  0.0113,  0.0436,  0.0764,\n",
      "          0.1100,  0.1449]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0225, -0.0187, -0.0149, -0.0110, -0.0072, -0.0034,  0.0005,  0.0043,\n",
      "          0.0082,  0.0120,  0.0158,  0.0197,  0.0235,  0.0273,  0.0312,  0.0350,\n",
      "          0.0389,  0.0427,  0.0465],\n",
      "        [-0.1003, -0.0942, -0.0877, -0.0809, -0.0736, -0.0660, -0.0579, -0.0495,\n",
      "         -0.0406, -0.0314, -0.0218, -0.0118, -0.0013,  0.0095,  0.0207,  0.0323,\n",
      "          0.0443,  0.0566,  0.0694]], device='cuda:0')\n",
      "LOSS tensor(37865.7773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 4 tensor([[-0.0838,  0.0171,  0.1176,  0.2122,  0.3006,  0.3864,  0.4694,  0.5473,\n",
      "          0.6195,  0.6891,  0.7533,  0.8172,  0.8774,  0.9372,  0.9965,  1.0561,\n",
      "          1.1171,  1.1778],\n",
      "        [-0.2069, -0.1935, -0.1676, -0.1276, -0.0718, -0.0033,  0.0753,  0.1649,\n",
      "          0.2629,  0.3680,  0.4755,  0.5802,  0.6858,  0.7940,  0.9066,  1.0142,\n",
      "          1.1186,  1.2259]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0724, -0.0155,  0.0413,  0.0981,  0.1549,  0.2117,  0.2685,  0.3253,\n",
      "          0.3821,  0.4389,  0.4957,  0.5525,  0.6093,  0.6661,  0.7230,  0.7798,\n",
      "          0.8366,  0.8934,  0.9502],\n",
      "        [-0.0999, -0.0935, -0.0812, -0.0631, -0.0392, -0.0095,  0.0261,  0.0675,\n",
      "          0.1147,  0.1678,  0.2267,  0.2914,  0.3620,  0.4384,  0.5206,  0.6087,\n",
      "          0.7026,  0.8024,  0.9079]], device='cuda:0')\n",
      "LOSS tensor(30764.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 5 tensor([[ 0.0044,  0.0317,  0.0584,  0.0850,  0.1114,  0.1379,  0.1642,  0.1908,\n",
      "          0.2170,  0.2432,  0.2692,  0.2951,  0.3208,  0.3461,  0.3710,  0.3955,\n",
      "          0.4196,  0.4437],\n",
      "        [-0.1279, -0.1137, -0.0958, -0.0745, -0.0492, -0.0200,  0.0125,  0.0482,\n",
      "          0.0866,  0.1281,  0.1729,  0.2211,  0.2727,  0.3241,  0.3753,  0.4279,\n",
      "          0.4811,  0.5358]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0225, -0.0021,  0.0182,  0.0386,  0.0590,  0.0794,  0.0998,  0.1202,\n",
      "          0.1406,  0.1610,  0.1814,  0.2018,  0.2222,  0.2426,  0.2630,  0.2834,\n",
      "          0.3038,  0.3242,  0.3446],\n",
      "        [-0.1002, -0.0924, -0.0825, -0.0705, -0.0565, -0.0403, -0.0221, -0.0017,\n",
      "          0.0207,  0.0452,  0.0719,  0.1006,  0.1314,  0.1643,  0.1993,  0.2364,\n",
      "          0.2756,  0.3169,  0.3603]], device='cuda:0')\n",
      "LOSS tensor(28195.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 6 tensor([[-0.2248, -0.1193, -0.0132,  0.0874,  0.1841,  0.2771,  0.3696,  0.4607,\n",
      "          0.5464,  0.6259,  0.6982,  0.7653,  0.8295,  0.8906,  0.9492,  1.0073,\n",
      "          1.0657,  1.1221],\n",
      "        [-0.1826, -0.1752, -0.1604, -0.1380, -0.1074, -0.0683, -0.0212,  0.0335,\n",
      "          0.0943,  0.1612,  0.2346,  0.3135,  0.3955,  0.4759,  0.5569,  0.6401,\n",
      "          0.7222,  0.8045]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0779, -0.0434, -0.0089,  0.0257,  0.0602,  0.0947,  0.1292,  0.1637,\n",
      "          0.1983,  0.2328,  0.2673,  0.3018,  0.3363,  0.3708,  0.4054,  0.4399,\n",
      "          0.4744,  0.5089,  0.5434],\n",
      "        [-0.1002, -0.0966, -0.0895, -0.0789, -0.0647, -0.0470, -0.0257, -0.0009,\n",
      "          0.0274,  0.0593,  0.0948,  0.1338,  0.1763,  0.2224,  0.2720,  0.3252,\n",
      "          0.3819,  0.4422,  0.5060]], device='cuda:0')\n",
      "LOSS tensor(21707.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 7 tensor([[-0.1524, -0.1949, -0.2361, -0.2760, -0.3156, -0.3541, -0.3924, -0.4304,\n",
      "         -0.4672, -0.5034, -0.5385, -0.5727, -0.6066, -0.6407, -0.6727, -0.7039,\n",
      "         -0.7351, -0.7652],\n",
      "        [-0.1067, -0.1093, -0.1146, -0.1225, -0.1330, -0.1462, -0.1620, -0.1806,\n",
      "         -0.2019, -0.2258, -0.2524, -0.2814, -0.3129, -0.3468, -0.3822, -0.4193,\n",
      "         -0.4576, -0.4973]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0778, -0.0967, -0.1157, -0.1346, -0.1535, -0.1724, -0.1913, -0.2102,\n",
      "         -0.2291, -0.2481, -0.2670, -0.2859, -0.3048, -0.3237, -0.3426, -0.3615,\n",
      "         -0.3804, -0.3994, -0.4183],\n",
      "        [-0.1004, -0.1023, -0.1062, -0.1120, -0.1198, -0.1295, -0.1411, -0.1547,\n",
      "         -0.1703, -0.1877, -0.2072, -0.2285, -0.2518, -0.2771, -0.3042, -0.3334,\n",
      "         -0.3644, -0.3975, -0.4324]], device='cuda:0')\n",
      "LOSS tensor(16405.5098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 8 tensor([[-0.0442,  0.0486,  0.1395,  0.2293,  0.3153,  0.3999,  0.4791,  0.5537,\n",
      "          0.6218,  0.6858,  0.7477,  0.8059,  0.8622,  0.9191,  0.9750,  1.0296,\n",
      "          1.0800,  1.1273],\n",
      "        [-0.1905, -0.1727, -0.1469, -0.1129, -0.0707, -0.0194,  0.0432,  0.1122,\n",
      "          0.1869,  0.2674,  0.3526,  0.4421,  0.5334,  0.6219,  0.7107,  0.8000,\n",
      "          0.8927,  0.9871]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0225,  0.0139,  0.0503,  0.0868,  0.1232,  0.1596,  0.1961,  0.2325,\n",
      "          0.2689,  0.3054,  0.3418,  0.3782,  0.4147,  0.4511,  0.4875,  0.5240,\n",
      "          0.5604,  0.5969,  0.6333],\n",
      "        [-0.1004, -0.0910, -0.0778, -0.0609, -0.0402, -0.0159,  0.0123,  0.0442,\n",
      "          0.0798,  0.1191,  0.1622,  0.2091,  0.2596,  0.3140,  0.3720,  0.4338,\n",
      "          0.4994,  0.5687,  0.6417]], device='cuda:0')\n",
      "LOSS tensor(11234.7080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 9 tensor([[-0.1363, -0.0689,  0.0016,  0.0695,  0.1349,  0.1983,  0.2598,  0.3206,\n",
      "          0.3802,  0.4377,  0.4900,  0.5398,  0.5889,  0.6369,  0.6823,  0.7261,\n",
      "          0.7694,  0.8123],\n",
      "        [-0.1920, -0.1853, -0.1719, -0.1516, -0.1243, -0.0900, -0.0466,  0.0047,\n",
      "          0.0617,  0.1234,  0.1897,  0.2609,  0.3375,  0.4177,  0.4946,  0.5724,\n",
      "          0.6521,  0.7286]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0779, -0.0470, -0.0162,  0.0146,  0.0455,  0.0763,  0.1071,  0.1380,\n",
      "          0.1688,  0.1996,  0.2305,  0.2613,  0.2922,  0.3230,  0.3538,  0.3847,\n",
      "          0.4155,  0.4463,  0.4772],\n",
      "        [-0.0999, -0.0967, -0.0904, -0.0809, -0.0682, -0.0524, -0.0334, -0.0112,\n",
      "          0.0141,  0.0426,  0.0743,  0.1091,  0.1471,  0.1883,  0.2326,  0.2801,\n",
      "          0.3308,  0.3846,  0.4416]], device='cuda:0')\n",
      "LOSS tensor(21800.3340, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder.cuda()\n",
    "rel_rec = rel_rec.cuda()\n",
    "rel_send = rel_send.cuda()\n",
    "from utils import *\n",
    "\n",
    "for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "    if batch_idx<10:\n",
    "        data, relations = data.cuda(), relations.cuda()\n",
    "        output, logits, all_msgs, msg = decoder(data, rel_rec, rel_send,\n",
    "                                 0.5, True, 1)\n",
    "#         print(output.size(), msg.size())\n",
    "#         print(msg[0,0,48], all_msgs[0,0,48])\n",
    "        print('jjjj',batch_idx, output[0,-2:,:,0], '\\n',data[0,-2:,:,0])\n",
    "        target = data[:, :, 1:, :] \n",
    "        loss_nll = nll_gaussian(output, target, 5e-5)\n",
    "        print('LOSS', loss_nll)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0]]], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = decoder.rel_graph.argmax(-1)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 1, 1, 56, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 3, 4, 5]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[3,4,5]])\n",
    "a.reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "f = np.load('data/edges_train_my.npy')\n",
    "print(f.shape)\n",
    "# for i in range(100):\n",
    "#     print(f[i,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 2]) tensor([[0.7129, 0.2871],\n",
      "        [0.7391, 0.2609],\n",
      "        [0.6699, 0.3301],\n",
      "        [0.7075, 0.2925],\n",
      "        [0.7343, 0.2657],\n",
      "        [0.7400, 0.2600],\n",
      "        [0.6815, 0.3185],\n",
      "        [0.6575, 0.3425],\n",
      "        [0.6697, 0.3303],\n",
      "        [0.7055, 0.2945],\n",
      "        [0.6904, 0.3096],\n",
      "        [0.5939, 0.4061],\n",
      "        [0.7636, 0.2364],\n",
      "        [0.7624, 0.2376],\n",
      "        [0.7765, 0.2235],\n",
      "        [0.7005, 0.2995],\n",
      "        [0.6995, 0.3005],\n",
      "        [0.7212, 0.2788],\n",
      "        [0.6454, 0.3546],\n",
      "        [0.7388, 0.2612],\n",
      "        [0.7167, 0.2833],\n",
      "        [0.6904, 0.3096],\n",
      "        [0.6721, 0.3279],\n",
      "        [0.6601, 0.3399],\n",
      "        [0.7401, 0.2599],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.7815, 0.2185],\n",
      "        [0.7477, 0.2523],\n",
      "        [0.7608, 0.2392],\n",
      "        [0.7764, 0.2236],\n",
      "        [0.6691, 0.3309],\n",
      "        [0.6239, 0.3761],\n",
      "        [0.6089, 0.3911],\n",
      "        [0.5886, 0.4114],\n",
      "        [0.5646, 0.4354],\n",
      "        [0.6082, 0.3918],\n",
      "        [0.6064, 0.3936],\n",
      "        [0.5322, 0.4678],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.4964, 0.5036],\n",
      "        [0.5823, 0.4177],\n",
      "        [0.4842, 0.5158]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rel_w = torch.Tensor(np.squeeze(np.load('logs/exp2020-06-30T19:33:14.071531/160_rel_graph.npy'))[0]).cuda()\n",
    "print(rel_w.size(), rel_w.softmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6996, 0.3004],\n",
       "        [0.6988, 0.3012],\n",
       "        [0.6934, 0.3066],\n",
       "        [0.7002, 0.2998],\n",
       "        [0.6991, 0.3009],\n",
       "        [0.6969, 0.3031],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6993, 0.3007],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6994, 0.3006],\n",
       "        [0.7002, 0.2998],\n",
       "        [0.6990, 0.3010],\n",
       "        [0.7005, 0.2995],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6982, 0.3018],\n",
       "        [0.6867, 0.3133],\n",
       "        [0.6986, 0.3014],\n",
       "        [0.6967, 0.3033],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6982, 0.3018],\n",
       "        [0.6973, 0.3027],\n",
       "        [0.6989, 0.3011],\n",
       "        [0.6933, 0.3067],\n",
       "        [0.6990, 0.3010],\n",
       "        [0.6935, 0.3065],\n",
       "        [0.6974, 0.3026],\n",
       "        [0.6959, 0.3041],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.6996, 0.3004],\n",
       "        [0.6969, 0.3031],\n",
       "        [0.6991, 0.3009],\n",
       "        [0.6995, 0.3005],\n",
       "        [0.6985, 0.3015],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6360, 0.3640],\n",
       "        [0.6223, 0.3777],\n",
       "        [0.4439, 0.5561],\n",
       "        [0.4107, 0.5893],\n",
       "        [0.6092, 0.3908],\n",
       "        [0.5939, 0.4061],\n",
       "        [0.5542, 0.4458],\n",
       "        [0.5935, 0.4065],\n",
       "        [0.5791, 0.4209],\n",
       "        [0.5709, 0.4291],\n",
       "        [0.4844, 0.5156],\n",
       "        [0.5939, 0.4061],\n",
       "        [0.4927, 0.5073],\n",
       "        [0.5772, 0.4228]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[s,c,friction,t,m,vel,loc]\n",
    "torch.Tensor(np.squeeze(np.load('logs/exp2020-06-30T21:28:03.944345/130_rel_graph.npy'))[0]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
