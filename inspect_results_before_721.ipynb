{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, name dim, Tensor out)\n      didn't match because some of the keywords were incorrect: dim\n * (tuple of Tensors tensors, int dim, Tensor out)\n      didn't match because some of the keywords were incorrect: dim\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f7893879eb87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, name dim, Tensor out)\n      didn't match because some of the keywords were incorrect: dim\n * (tuple of Tensors tensors, int dim, Tensor out)\n      didn't match because some of the keywords were incorrect: dim\n"
     ]
    }
   ],
   "source": [
    "num_nodes=7\n",
    "edge_types=2\n",
    "a = torch.zeros((1, 1, num_nodes*(num_nodes-2), edge_types), requires_grad=True, device=\"cuda\")\n",
    "b = torch.zeros((1, 1, 1, edge_types), requires_grad=False, device=\"cuda\")\n",
    "b[:,:,:,0]=1\n",
    "c = torch.zeros((1, 1, num_nodes-1, edge_types), requires_grad=True, device=\"cuda\")\n",
    "d=torch.zeros((1, 1, num_nodes, edge_types), requires_grad=True, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 7, 19, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load('data/feat_valid_causal_vel.npy')\n",
    "x.shape\n",
    "new_time=np.zeros((1,19,9))\n",
    "new_time[:,:,0]=np.linspace(0,36,19)\n",
    "new_time[:,:,-1]=1\n",
    "time=np.tile(np.expand_dims(new_time, 0),(x.shape[0],1,1,1))\n",
    "time.shape\n",
    "final=np.zeros((x.shape[0], x.shape[1]+1, x.shape[2], x.shape[3]+1))\n",
    "final[:,:-1,:,:-1]=x\n",
    "final[:,-1:,:,:]=time\n",
    "np.save('data/feat_valid_causal_vel_time.npy', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 40\n",
      "1 57\n",
      "1 213\n",
      "1 9\n",
      "1 254\n"
     ]
    }
   ],
   "source": [
    "#[num_sims, num_atoms, num_timesteps, num_dims] 5x5x5x5,5,4,1\n",
    "step=19\n",
    "interval=2\n",
    "data=[]\n",
    "for shape in [1,2,3]:\n",
    "    s=[[shape,1,0,0,0,0,0,0]]*step\n",
    "    for color in :\n",
    "        print(shape,color)\n",
    "        c=[[color,0,1,0,0,0,0,0]]*step\n",
    "        for mu in mus:\n",
    "            friction = [[mu,0,0,1,0,0,0,0]]*step\n",
    "            for theta in thetas:\n",
    "                t = [[theta,0,0,0,1,0,0,0]]*step\n",
    "                for mass in masses:\n",
    "                    m = [[mass,0,0,0,0,1,0,0]]*step\n",
    "                    for u0 in u0s:\n",
    "#                         u = [u0]*step\n",
    "                        for v0 in v0s:\n",
    "#                             v = [v0]*step\n",
    "                            loc = np.zeros((step, 8))\n",
    "                            loc[0,0] = u0\n",
    "                            loc[:,1:] =[0,0,0,0,0,0,1]\n",
    "                            vel = np.zeros((step, 8))\n",
    "                            vel[0,0] = v0\n",
    "                            vel[:,1:] =[0,0,0,0,0,1,0]\n",
    "                            for i in range(1, step):\n",
    "                                loc[i, 0]=loc[i-1, 0]+vel[i-1,0]*interval+0.5*g*(np.sin(theta)-np.cos(theta)*mu)*(interval**2)\n",
    "                                vel[i, 0] = vel[i-1, 0]+g*(np.sin(theta)-np.cos(theta)*mu)\n",
    "                            #monitor the loss of vel_curr,loc_curr, \n",
    "                            #each dim 1+one_hot_semantic=9\n",
    "                            #self.rel_graph=8x8\n",
    "                            #\n",
    "                            #[s,c,friction,t,m,vel_curr,loc_curr], [s,c,friction,t,m, [loc_prevs]]\n",
    "                            trial=np.stack([s,c,friction,t,m,vel,loc],axis=0) \n",
    "                            data.append(trial)\n",
    "                            \n",
    "                          \n",
    "                            \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[num_sims, num_atoms, num_timesteps, num_dims] 5x5x5x5,5,4,1\n",
    "step=19\n",
    "interval=2\n",
    "data=[]\n",
    "for shape in [1,2,3]:\n",
    "    s=[shape]*step\n",
    "    for color in [40,57,213,9,254]:\n",
    "        c=[color]*step\n",
    "        for mu in mus:\n",
    "            friction = [mu]*step\n",
    "            for theta in thetas:\n",
    "                t = [theta]*step\n",
    "                for mass in masses:\n",
    "                    m = [mass]*step\n",
    "                    for u0 in u0s:\n",
    "#                         u = [u0]*step\n",
    "                        for v0 in v0s:\n",
    "#                             v = [v0]*step\n",
    "                            loc = np.zeros(step)\n",
    "                            loc[0] = u0\n",
    "#                             loc[:,1:] =[0,0,0,0,0,0,1]\n",
    "                            vel = np.zeros(step)\n",
    "                            vel[0] = v0\n",
    "#                             vel[:,1:] =[0,0,0,0,0,1,0]\n",
    "                            for i in range(1, step):\n",
    "                                loc[i]=loc[i-1]+vel[i-1]*interval+0.5*g*(np.sin(theta)-np.cos(theta)*mu)*(interval**2)\n",
    "                                vel[i] = vel[i-1]+g*(np.sin(theta)-np.cos(theta)*mu)\n",
    "                            #monitor the loss of vel_curr,loc_curr, \n",
    "                            #each dim 1+one_hot_semantic=9\n",
    "                            #self.rel_graph=8x8\n",
    "                            #\n",
    "                            #[s,c,friction,t,m,vel_curr,loc_curr], [s,c,friction,t,m, [loc_prevs]]\n",
    "                            trial=np.stack([s,c,friction,t,m,vel,loc],axis=0) \n",
    "                            data.append(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67500, 7, 19, 8)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_data=np.expand_dims(np.array(data),-1)\n",
    "data_new=np.array(data)\n",
    "# new_data.shape\n",
    "# data_new=new_data\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [4.00000000e+01],\n",
       "       [1.00000000e-03],\n",
       "       [3.49065850e-02],\n",
       "       [5.00000000e-01],\n",
       "       [6.64442075e-01],\n",
       "       [2.09332623e+00]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new[0,:,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 9, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge=np.array([[0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0,0]])  \n",
    "# edge=np.array([[0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0],\\\n",
    "#                [0,0,0,0,0,0,1],\\\n",
    "#                [0,0,0,0,0,0,0]]) \n",
    "edge=np.repeat(np.expand_dims(edge,0),data_new_1.shape[0],axis=0)\n",
    "edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9323 102535 350601  22294 372254 527304  49301  31565 175517 497442]\n"
     ]
    }
   ],
   "source": [
    "data_new_1=data_new[:600000]\n",
    "arr=np.arange(data_new_1.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "print(arr[:10])\n",
    "start_1 = int(data_new_1.shape[0]*0.75)\n",
    "start_2 = int(data_new_1.shape[0]*0.85)\n",
    "np.save('data/feat_train_causal_vel_sincos.npy',data_new_1[arr[:start_1]])\n",
    "np.save('data/feat_valid_causal_vel_sincos.npy',data_new_1[arr[start_1:start_2]])\n",
    "np.save('data/feat_test_causal_vel_sincos.npy',data_new_1[arr[start_2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_1 = int(600000*0.75)\n",
    "start_2 = int(600000*0.85)\n",
    "np.save('data/edges_train_causal_vel_sincos.npy',edge[:start_1])\n",
    "np.save('data/edges_valid_causal_vel_sincos.npy',edge[start_1:start_2])\n",
    "np.save('data/edges_test_causal_vel_sincos.npy',edge[start_2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.zeros_like(data)\n",
    "for i in range(0, data.shape[1]):\n",
    "        new_data[:,i,:,:] = (data[:,i,:,:] - np.min(data[:,i,:,:]))*2/(np.max(data[:,i,:,:])-np.min(data[:,i,:,:]))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(new_data[:,2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = np.squeeze(np.load('logs/exp2020-06-27T06:41:05.204948/100_rel_graph_grad.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 56, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " debug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4561, 0.5439],\n",
       "        [0.4784, 0.5216],\n",
       "        [0.4419, 0.5581],\n",
       "        [0.5065, 0.4935],\n",
       "        [0.5450, 0.4550],\n",
       "        [0.4704, 0.5296],\n",
       "        [0.4956, 0.5044],\n",
       "        [0.4326, 0.5674],\n",
       "        [0.4694, 0.5306],\n",
       "        [0.5221, 0.4779],\n",
       "        [0.5498, 0.4502],\n",
       "        [0.4617, 0.5383],\n",
       "        [0.5222, 0.4778],\n",
       "        [0.5739, 0.4261],\n",
       "        [0.5347, 0.4653],\n",
       "        [0.4973, 0.5027],\n",
       "        [0.4888, 0.5112],\n",
       "        [0.5077, 0.4923],\n",
       "        [0.4504, 0.5496],\n",
       "        [0.5579, 0.4421],\n",
       "        [0.5229, 0.4771],\n",
       "        [0.5078, 0.4922],\n",
       "        [0.5242, 0.4758],\n",
       "        [0.4749, 0.5251],\n",
       "        [0.5070, 0.4930],\n",
       "        [0.4725, 0.5275],\n",
       "        [0.5110, 0.4890],\n",
       "        [0.5580, 0.4420],\n",
       "        [0.5095, 0.4905],\n",
       "        [0.5257, 0.4743],\n",
       "        [0.5509, 0.4491],\n",
       "        [0.5185, 0.4815],\n",
       "        [0.5544, 0.4456],\n",
       "        [0.5458, 0.4542],\n",
       "        [0.4814, 0.5186],\n",
       "        [0.4988, 0.5012],\n",
       "        [0.4573, 0.5427],\n",
       "        [0.4657, 0.5343],\n",
       "        [0.4529, 0.5471],\n",
       "        [0.4738, 0.5262],\n",
       "        [0.5055, 0.4945],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.5020, 0.4980],\n",
       "        [0.4962, 0.5038],\n",
       "        [0.5431, 0.4569],\n",
       "        [0.4895, 0.5105],\n",
       "        [0.4838, 0.5162],\n",
       "        [0.4997, 0.5003],\n",
       "        [0.5111, 0.4889],\n",
       "        [0.5454, 0.4546],\n",
       "        [0.4634, 0.5366],\n",
       "        [0.5051, 0.4949],\n",
       "        [0.5337, 0.4663],\n",
       "        [0.4759, 0.5241],\n",
       "        [0.4905, 0.5095],\n",
       "        [0.5431, 0.4569]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T06:41:05.204948/0_rel_graph.npy'))[0]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.squeeze(np.load('logs/exp2020-06-27T06:41:05.204948/10_rel_graph.npy'))[0]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6],\n",
       "        [ 7],\n",
       "        [20],\n",
       "        [49],\n",
       "        [50],\n",
       "        [51],\n",
       "        [52],\n",
       "        [53],\n",
       "        [54],\n",
       "        [55]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt: 20,27,41,48\n",
    "torch.nonzero(F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T19:11:06.878733/20_rel_graph.npy'))[0]),dim=1).argmax(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7402, 0.2598],\n",
       "        [0.7477, 0.2523],\n",
       "        [0.7370, 0.2630],\n",
       "        [0.7531, 0.2469],\n",
       "        [0.7642, 0.2358],\n",
       "        [0.7428, 0.2572],\n",
       "        [0.7183, 0.2817],\n",
       "        [0.6943, 0.3057],\n",
       "        [0.7546, 0.2454],\n",
       "        [0.7804, 0.2196],\n",
       "        [0.7771, 0.2229],\n",
       "        [0.7500, 0.2500],\n",
       "        [0.7788, 0.2212],\n",
       "        [0.7915, 0.2085],\n",
       "        [0.7376, 0.2624],\n",
       "        [0.7285, 0.2715],\n",
       "        [0.7316, 0.2684],\n",
       "        [0.7282, 0.2718],\n",
       "        [0.7312, 0.2688],\n",
       "        [0.7713, 0.2287],\n",
       "        [0.7114, 0.2886],\n",
       "        [0.7461, 0.2539],\n",
       "        [0.7513, 0.2487],\n",
       "        [0.7420, 0.2580],\n",
       "        [0.7439, 0.2561],\n",
       "        [0.7412, 0.2588],\n",
       "        [0.7507, 0.2493],\n",
       "        [0.7540, 0.2460],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7010, 0.2990],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7011, 0.2989],\n",
       "        [0.7012, 0.2988],\n",
       "        [0.7005, 0.2995],\n",
       "        [0.7259, 0.2741],\n",
       "        [0.7280, 0.2720],\n",
       "        [0.7234, 0.2766],\n",
       "        [0.7309, 0.2691],\n",
       "        [0.7267, 0.2733],\n",
       "        [0.7332, 0.2668],\n",
       "        [0.7195, 0.2805],\n",
       "        [0.7166, 0.2834],\n",
       "        [0.7147, 0.2853],\n",
       "        [0.7166, 0.2834],\n",
       "        [0.7146, 0.2854],\n",
       "        [0.7158, 0.2842],\n",
       "        [0.7159, 0.2841],\n",
       "        [0.7057, 0.2943],\n",
       "        [0.3017, 0.6983],\n",
       "        [0.2164, 0.7836],\n",
       "        [0.2134, 0.7866],\n",
       "        [0.1982, 0.8018],\n",
       "        [0.2129, 0.7871],\n",
       "        [0.2459, 0.7541],\n",
       "        [0.2430, 0.7570]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.Tensor(np.squeeze(np.load('../NRI/logs/exp2020-06-27T18:33:05.207373/150_rel_graph.npy'))[0]),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3916e-02, -2.3916e-02],\n",
       "        [ 4.6865e-02, -4.6865e-02],\n",
       "        [ 2.3737e-03, -2.3737e-03],\n",
       "        [ 5.2621e-04, -5.2621e-04],\n",
       "        [ 4.8675e-03, -4.8675e-03],\n",
       "        [ 2.5948e-02, -2.5948e-02],\n",
       "        [ 2.2249e-02, -2.2249e-02],\n",
       "        [-6.3811e-03,  6.3811e-03],\n",
       "        [-1.6867e-02,  1.6867e-02],\n",
       "        [-1.5393e-05,  1.5393e-05],\n",
       "        [-1.2491e-04,  1.2491e-04],\n",
       "        [-1.4796e-02,  1.4796e-02],\n",
       "        [-2.1448e-04,  2.1448e-04],\n",
       "        [-3.7762e-02,  3.7762e-02],\n",
       "        [-6.6433e-02,  6.6433e-02],\n",
       "        [-1.5416e-02,  1.5416e-02],\n",
       "        [-6.8907e-02,  6.8907e-02],\n",
       "        [-2.8558e-02,  2.8558e-02],\n",
       "        [-4.3664e-02,  4.3664e-02],\n",
       "        [-2.3036e-04,  2.3036e-04],\n",
       "        [-9.6356e-02,  9.6356e-02],\n",
       "        [-2.9030e-02,  2.9030e-02],\n",
       "        [-1.7885e-02,  1.7885e-02],\n",
       "        [-3.3899e-02,  3.3899e-02],\n",
       "        [-2.9378e-02,  2.9378e-02],\n",
       "        [-2.8083e-02,  2.8083e-02],\n",
       "        [-2.0533e-02,  2.0533e-02],\n",
       "        [-1.2789e-03,  1.2789e-03],\n",
       "        [-3.8094e-03,  3.8094e-03],\n",
       "        [-8.5271e-03,  8.5271e-03],\n",
       "        [-2.7183e-03,  2.7183e-03],\n",
       "        [-1.4224e-02,  1.4224e-02],\n",
       "        [-2.0973e-03,  2.0973e-03],\n",
       "        [-7.8611e-05,  7.8614e-05],\n",
       "        [-4.6543e-03,  4.6543e-03],\n",
       "        [-1.9400e+00,  1.9400e+00],\n",
       "        [-1.7349e+00,  1.7349e+00],\n",
       "        [-1.4441e-01,  1.4441e-01],\n",
       "        [-5.3339e+00,  5.3339e+00],\n",
       "        [-2.5113e+00,  2.5113e+00],\n",
       "        [-2.1138e+00,  2.1138e+00],\n",
       "        [-4.5610e-01,  4.5610e-01],\n",
       "        [-6.3432e-03,  6.3432e-03],\n",
       "        [-1.1211e-03,  1.1211e-03],\n",
       "        [-1.5246e-03,  1.5246e-03],\n",
       "        [-9.0128e-04,  9.0128e-04],\n",
       "        [-1.2785e-02,  1.2785e-02],\n",
       "        [-2.8390e-03,  2.8390e-03],\n",
       "        [-4.1784e-04,  4.1784e-04],\n",
       "        [ 9.1436e+00, -9.1436e+00],\n",
       "        [ 1.3748e+01, -1.3748e+01],\n",
       "        [ 1.2076e+01, -1.2076e+01],\n",
       "        [ 4.6654e-02, -4.6654e-02],\n",
       "        [ 5.0630e+00, -5.0630e+00],\n",
       "        [ 5.1234e+00, -5.1234e+00],\n",
       "        [ 1.7032e+00, -1.7031e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.squeeze(np.load('logs/exp2020-06-27T18:20:43.181813/0_rel_graph_grad.npy'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.Tensor([[[1,2,3],[4,5,6]]])\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.Tensor([[[1],[0]]])\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from modules_causal import *\n",
    "\n",
    "class MLPDecoder_Causal_1(nn.Module):\n",
    "    \"\"\"MLP decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,\n",
    "                 do_prob=0., skip_first=False, cuda=True, num_nodes=8, pred_steps=1):\n",
    "        super(MLPDecoder_Causal_1, self).__init__()\n",
    "        \n",
    "        #TODO: only the last col of the original adj matrix will be trained   \n",
    "        if cuda:\n",
    "            self.rel_graph = torch.zeros((1, 1, num_nodes**2, edge_types), requires_grad=True, device=\"cuda\")\n",
    "#             self.zeros = torch.zeros((1, 1, (num_nodes-1)**2, edge_types), requires_grad=False, device=\"cuda\")\n",
    "#             self.all = torch.cat((self.zeros,self.rel_graph),dim=2)\n",
    "        else:\n",
    "            self.rel_graph = torch.zeros((1, 1, num_nodes*(num_nodes-1), edge_types), requires_grad=True)\n",
    "#         import pdb;pdb.set_trace()\n",
    "        \n",
    "        nn.init.xavier_normal_(self.rel_graph)\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_types = edge_types\n",
    "#         for i in range(0,num_nodes*(num_nodes-1)+1, num_nodes-1):\n",
    "#             self.rel_graph[:,:,i,:]=random.random()\n",
    "   \n",
    "            \n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)])\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "        #dim small to large to small\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send, \n",
    "                            single_timestep_rel_type):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        #pre_msg bs,timesteps, num_atoms*(num_atoms-1), 2\n",
    "#         print('rel_rec',rel_rec)\n",
    "#         print('rel_send', rel_send)\n",
    "\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
    "                                        pre_msg.size(2), self.msg_out_shape))\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "#         print('ffffff', single_timestep_inputs[0,0].size(), pre_msg[0,0].size())\n",
    "#         print('ffffff', single_timestep_inputs[0,0], pre_msg[0,0])\n",
    "            \n",
    "\n",
    "#         test=torch.zeros((1,1,56,1)).cuda()  51,52,54,55\n",
    "#         test[:,:,20,:]=1\n",
    "#         test[:,:,27,:]=1\n",
    "#         test[:,:,41,:]=1\n",
    "#         test[:,:,48,:]=1\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exlude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            print('start', i)\n",
    "            \n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            #single_timestep_rel_type bs, pred_steps, #node*(#node-1), #edge_type\n",
    "            #msg bs, pred_steps, #node*(#node-1), self.msg_out_shape=256\n",
    "            msg_after = msg * single_timestep_rel_type[:, :, :, i:i + 1]\n",
    "#             print('here',torch.nonzero(single_timestep_rel_type[:, :, :, i:i + 1]))\n",
    "#             msg_after = msg * self.rel_graph[:, :, :, i:i + 1]\n",
    "            all_msgs += msg_after\n",
    "            \n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        #agg_msg bs, pred_steps, #node, self.msg_out_shape=256\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        #msg bs, pred_steps, #node, self.msg_out_shape+1=257\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        #in:256, out:1\n",
    "        pred = self.out_fc3(pred)\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred, msg_after, msg\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send, tau, hard, pred_steps):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "#         logits = self.rel_graph # (inputs, rel_rec, rel_send)\n",
    "        edges = gumbel_softmax(self.rel_graph, tau, hard)\n",
    "        \n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "#         sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),\n",
    "#                  rel_type.size(2)]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "#         rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert (pred_steps <= time_steps)\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps) 5\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "\n",
    "#         curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps): \n",
    "            last_pred, all_msgs, msg = self.single_step_forward(last_pred, rel_rec, rel_send, edges)\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,\n",
    "                 preds[0].size(2), preds[0].size(3)]\n",
    "\n",
    "        output = Variable(torch.zeros(sizes))\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)): #10\n",
    "            #5 fixed points, 10 each sequence. preds[i] means the ith of each sequence.\n",
    "            output[:, i::pred_steps, :, :] = preds[i] \n",
    "        pred_all = output[:, :(inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous(), \\\n",
    "    self.rel_graph.squeeze(1).expand([inputs.size(0), self.num_nodes**2, self.edge_types]), all_msgs, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learned interaction net decoder.\n"
     ]
    }
   ],
   "source": [
    "decoder = MLPDecoder_Causal_1(n_in_node=8,\n",
    "                         edge_types=2,\n",
    "                         msg_hid=256,\n",
    "                         msg_out=256,\n",
    "                         n_hid=256,\n",
    "                         do_prob=0,\n",
    "                         skip_first=True,\n",
    "                         cuda=True,\n",
    "                         num_nodes=7)\n",
    "# rel_w = torch.load('logs/exp2020-07-04T02:16:59.482117/decoder.pt')[1]\n",
    "# decoder.rel_graph = torch.Tensor(rel_w).cuda()\n",
    "# decoder.load_state_dict(torch.load('logs/exp2020-07-04T02:16:59.482117/decoder.pt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.load_state_dict(torch.load('logs/exp2020-07-04T02:16:59.482117/decoder.pt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.rel_graph =torch.load('logs/exp2020-07-04T02:16:59.482117/decoder.pt')[1]\n",
    "decoder.rel_graph.argmax(-1).view((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-be9be9e061db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loader, valid_loader, test_loader = load_my_data(batch_size=128, \n\u001b[0;32m----> 2\u001b[0;31m                                                        suffix='_causal_vel')\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate off-diagonal interaction graph, ones with only zeros on diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CausalPhys/utils.py\u001b[0m in \u001b[0;36mload_my_data\u001b[0;34m(batch_size, suffix, self_loop)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;31m#         print(i, np.max(feat_train[:,i,:,:]), np.min(feat_train[:,i,:,:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mfeat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;31m#         print(i, np.max(feat_valid[:,i,:,:]), np.min(feat_valid[:,i,:,:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mfeat_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cmr/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cmr/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_my_data(batch_size=128, \n",
    "                                                       suffix='_causal_vel')\n",
    "\n",
    "\n",
    "# Generate off-diagonal interaction graph, ones with only zeros on diagonal\n",
    "off_diag = np.ones([7, 7]) #- np.eye(7)\n",
    "# This is not adjacency matrix since it's 56*8, not 8*8!\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1\n",
      "jjjj 0 tensor([[-0.0300, -0.0412, -0.0526, -0.0645, -0.0766, -0.0889, -0.1013, -0.1139,\n",
      "         -0.1266, -0.1398, -0.1534, -0.1663, -0.1789, -0.1915, -0.2040, -0.2169,\n",
      "         -0.2300, -0.2433],\n",
      "        [-0.0616, -0.0616, -0.0624, -0.0647, -0.0688, -0.0742, -0.0804, -0.0885,\n",
      "         -0.0970, -0.1065, -0.1168, -0.1281, -0.1407, -0.1542, -0.1690, -0.1851,\n",
      "         -0.2031, -0.2225]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0272, -0.0398, -0.0523, -0.0649, -0.0774, -0.0900, -0.1025, -0.1151,\n",
      "         -0.1276, -0.1402, -0.1527, -0.1653, -0.1778, -0.1904, -0.2029, -0.2155,\n",
      "         -0.2280, -0.2406],\n",
      "        [-0.0644, -0.0632, -0.0633, -0.0647, -0.0674, -0.0714, -0.0767, -0.0833,\n",
      "         -0.0911, -0.1003, -0.1108, -0.1226, -0.1357, -0.1501, -0.1658, -0.1828,\n",
      "         -0.2011, -0.2207]], device='cuda:0')\n",
      "LOSS tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 1 tensor([[-0.0270, -0.0203, -0.0137, -0.0069, -0.0002,  0.0065,  0.0129,  0.0193,\n",
      "          0.0259,  0.0324,  0.0391,  0.0458,  0.0522,  0.0586,  0.0649,  0.0713,\n",
      "          0.0775,  0.0839],\n",
      "        [-0.0666, -0.0651, -0.0632, -0.0608, -0.0578, -0.0542, -0.0500, -0.0451,\n",
      "         -0.0395, -0.0334, -0.0267, -0.0196, -0.0118, -0.0034,  0.0062,  0.0164,\n",
      "          0.0276,  0.0400]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0453, -0.0392, -0.0331, -0.0270, -0.0209, -0.0148, -0.0087, -0.0026,\n",
      "          0.0035,  0.0096,  0.0157,  0.0218,  0.0279,  0.0340,  0.0401,  0.0462,\n",
      "          0.0523,  0.0584],\n",
      "        [-0.0662, -0.0650, -0.0631, -0.0606, -0.0574, -0.0536, -0.0492, -0.0441,\n",
      "         -0.0384, -0.0321, -0.0252, -0.0176, -0.0094, -0.0005,  0.0089,  0.0190,\n",
      "          0.0298,  0.0412]], device='cuda:0')\n",
      "LOSS tensor(7.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 2 tensor([[-0.0399, -0.0269, -0.0138, -0.0007,  0.0119,  0.0244,  0.0374,  0.0504,\n",
      "          0.0634,  0.0765,  0.0893,  0.1021,  0.1150,  0.1278,  0.1404,  0.1530,\n",
      "          0.1659,  0.1790],\n",
      "        [-0.0660, -0.0610, -0.0552, -0.0484, -0.0411, -0.0327, -0.0233, -0.0127,\n",
      "         -0.0010,  0.0118,  0.0256,  0.0408,  0.0574,  0.0765,  0.0968,  0.1181,\n",
      "          0.1400,  0.1631]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0387, -0.0259, -0.0132, -0.0005,  0.0122,  0.0250,  0.0377,  0.0504,\n",
      "          0.0632,  0.0759,  0.0886,  0.1013,  0.1141,  0.1268,  0.1395,  0.1522,\n",
      "          0.1650,  0.1777],\n",
      "        [-0.0656, -0.0629, -0.0590, -0.0537, -0.0471, -0.0392, -0.0300, -0.0195,\n",
      "         -0.0076,  0.0056,  0.0201,  0.0359,  0.0530,  0.0715,  0.0912,  0.1123,\n",
      "          0.1347,  0.1584]], device='cuda:0')\n",
      "LOSS tensor(1.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 3 tensor([[-4.0576e-02, -7.6086e-03,  2.5534e-02,  5.9029e-02,  9.2551e-02,\n",
      "          1.2475e-01,  1.5619e-01,  1.8765e-01,  2.1940e-01,  2.5113e-01,\n",
      "          2.8291e-01,  3.1493e-01,  3.4696e-01,  3.7936e-01,  4.1153e-01,\n",
      "          4.4240e-01,  4.7308e-01,  5.0356e-01],\n",
      "        [-5.7362e-02, -5.3120e-02, -4.5303e-02, -3.3931e-02, -1.8716e-02,\n",
      "         -1.9129e-05,  2.2313e-02,  4.8678e-02,  7.8878e-02,  1.1230e-01,\n",
      "          1.4904e-01,  1.8926e-01,  2.3204e-01,  2.7701e-01,  3.2450e-01,\n",
      "          3.7470e-01,  4.2610e-01,  4.7974e-01]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0202,  0.0109,  0.0421,  0.0732,  0.1044,  0.1355,  0.1667,  0.1978,\n",
      "          0.2290,  0.2602,  0.2913,  0.3225,  0.3536,  0.3848,  0.4159,  0.4471,\n",
      "          0.4782,  0.5094],\n",
      "        [-0.0636, -0.0571, -0.0474, -0.0345, -0.0184,  0.0009,  0.0235,  0.0493,\n",
      "          0.0784,  0.1106,  0.1461,  0.1848,  0.2267,  0.2719,  0.3203,  0.3719,\n",
      "          0.4267,  0.4848]], device='cuda:0')\n",
      "LOSS tensor(3.5047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 4 tensor([[-0.0311, -0.0083,  0.0142,  0.0363,  0.0583,  0.0802,  0.1023,  0.1242,\n",
      "          0.1462,  0.1680,  0.1898,  0.2119,  0.2344,  0.2572,  0.2803,  0.3034,\n",
      "          0.3263,  0.3492],\n",
      "        [-0.0586, -0.0556, -0.0502, -0.0423, -0.0319, -0.0192, -0.0040,  0.0139,\n",
      "          0.0344,  0.0576,  0.0838,  0.1121,  0.1426,  0.1749,  0.2096,  0.2468,\n",
      "          0.2864,  0.3263]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0292, -0.0070,  0.0151,  0.0373,  0.0595,  0.0817,  0.1038,  0.1260,\n",
      "          0.1482,  0.1704,  0.1925,  0.2147,  0.2369,  0.2590,  0.2812,  0.3034,\n",
      "          0.3256,  0.3477],\n",
      "        [-0.0646, -0.0600, -0.0531, -0.0439, -0.0324, -0.0187, -0.0026,  0.0158,\n",
      "          0.0364,  0.0594,  0.0847,  0.1122,  0.1420,  0.1742,  0.2086,  0.2454,\n",
      "          0.2844,  0.3257]], device='cuda:0')\n",
      "LOSS tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 5 tensor([[-0.0492, -0.0272, -0.0051,  0.0181,  0.0420,  0.0674,  0.0925,  0.1171,\n",
      "          0.1409,  0.1640,  0.1882,  0.2145,  0.2423,  0.2720,  0.3060,  0.3382,\n",
      "          0.3667,  0.3927],\n",
      "        [-0.0646, -0.0590, -0.0506, -0.0400, -0.0283, -0.0142,  0.0021,  0.0215,\n",
      "          0.0432,  0.0674,  0.0940,  0.1231,  0.1547,  0.1886,  0.2247,  0.2642,\n",
      "          0.3072,  0.3509]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0252, -0.0023,  0.0206,  0.0436,  0.0665,  0.0894,  0.1123,  0.1352,\n",
      "          0.1581,  0.1810,  0.2039,  0.2268,  0.2497,  0.2726,  0.2955,  0.3184,\n",
      "          0.3413,  0.3642],\n",
      "        [-0.0641, -0.0590, -0.0515, -0.0417, -0.0295, -0.0149,  0.0020,  0.0213,\n",
      "          0.0430,  0.0671,  0.0935,  0.1223,  0.1535,  0.1870,  0.2229,  0.2612,\n",
      "          0.3019,  0.3449]], device='cuda:0')\n",
      "LOSS tensor(9.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 6 tensor([[-0.0390, -0.0233, -0.0076,  0.0079,  0.0230,  0.0385,  0.0538,  0.0689,\n",
      "          0.0840,  0.0987,  0.1133,  0.1278,  0.1422,  0.1566,  0.1711,  0.1859,\n",
      "          0.2005,  0.2151],\n",
      "        [-0.0660, -0.0602, -0.0533, -0.0458, -0.0372, -0.0275, -0.0166, -0.0044,\n",
      "          0.0090,  0.0238,  0.0403,  0.0584,  0.0787,  0.1003,  0.1232,  0.1471,\n",
      "          0.1726,  0.1996]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0365, -0.0216, -0.0067,  0.0082,  0.0231,  0.0379,  0.0528,  0.0677,\n",
      "          0.0826,  0.0975,  0.1123,  0.1272,  0.1421,  0.1570,  0.1719,  0.1867,\n",
      "          0.2016,  0.2165],\n",
      "        [-0.0653, -0.0622, -0.0576, -0.0515, -0.0437, -0.0345, -0.0237, -0.0114,\n",
      "          0.0025,  0.0179,  0.0349,  0.0533,  0.0734,  0.0950,  0.1181,  0.1427,\n",
      "          0.1689,  0.1966]], device='cuda:0')\n",
      "LOSS tensor(1.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 7 tensor([[-0.0469, -0.0445, -0.0420, -0.0396, -0.0372, -0.0347, -0.0323, -0.0298,\n",
      "         -0.0274, -0.0250, -0.0226, -0.0201, -0.0177, -0.0153, -0.0129, -0.0105,\n",
      "         -0.0080, -0.0056],\n",
      "        [-0.0643, -0.0636, -0.0626, -0.0613, -0.0598, -0.0581, -0.0561, -0.0538,\n",
      "         -0.0513, -0.0485, -0.0455, -0.0422, -0.0387, -0.0349, -0.0308, -0.0265,\n",
      "         -0.0219, -0.0171]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0453, -0.0429, -0.0405, -0.0381, -0.0357, -0.0332, -0.0308, -0.0284,\n",
      "         -0.0260, -0.0236, -0.0212, -0.0188, -0.0164, -0.0140, -0.0115, -0.0091,\n",
      "         -0.0067, -0.0043],\n",
      "        [-0.0662, -0.0653, -0.0642, -0.0628, -0.0611, -0.0593, -0.0571, -0.0548,\n",
      "         -0.0521, -0.0493, -0.0461, -0.0428, -0.0391, -0.0353, -0.0311, -0.0268,\n",
      "         -0.0221, -0.0173]], device='cuda:0')\n",
      "LOSS tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 8 tensor([[-0.0745, -0.1034, -0.1327, -0.1619, -0.1917, -0.2201, -0.2490, -0.2786,\n",
      "         -0.3075, -0.3366, -0.3654, -0.3939, -0.4228, -0.4519, -0.4808, -0.5095,\n",
      "         -0.5386, -0.5685],\n",
      "        [-0.0674, -0.0729, -0.0821, -0.0949, -0.1102, -0.1268, -0.1460, -0.1683,\n",
      "         -0.1938, -0.2231, -0.2557, -0.2912, -0.3293, -0.3707, -0.4150, -0.4612,\n",
      "         -0.5095, -0.5601]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0768, -0.1056, -0.1344, -0.1631, -0.1919, -0.2206, -0.2494, -0.2782,\n",
      "         -0.3069, -0.3357, -0.3644, -0.3932, -0.4220, -0.4507, -0.4795, -0.5082,\n",
      "         -0.5370, -0.5658],\n",
      "        [-0.0694, -0.0750, -0.0836, -0.0952, -0.1098, -0.1273, -0.1478, -0.1713,\n",
      "         -0.1977, -0.2272, -0.2596, -0.2950, -0.3333, -0.3747, -0.4190, -0.4663,\n",
      "         -0.5166, -0.5699]], device='cuda:0')\n",
      "LOSS tensor(0.5944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "start 1\n",
      "jjjj 9 tensor([[-0.0416, -0.0356, -0.0295, -0.0234, -0.0171, -0.0110, -0.0048,  0.0013,\n",
      "          0.0075,  0.0138,  0.0201,  0.0265,  0.0329,  0.0394,  0.0457,  0.0522,\n",
      "          0.0587,  0.0654],\n",
      "        [-0.0666, -0.0647, -0.0625, -0.0596, -0.0561, -0.0519, -0.0472, -0.0416,\n",
      "         -0.0354, -0.0285, -0.0211, -0.0131, -0.0046,  0.0044,  0.0139,  0.0244,\n",
      "          0.0358,  0.0482]], device='cuda:0', grad_fn=<SelectBackward>) \n",
      " tensor([[-0.0416, -0.0355, -0.0294, -0.0233, -0.0172, -0.0111, -0.0050,  0.0011,\n",
      "          0.0072,  0.0133,  0.0194,  0.0255,  0.0316,  0.0377,  0.0438,  0.0499,\n",
      "          0.0560,  0.0621],\n",
      "        [-0.0657, -0.0641, -0.0618, -0.0589, -0.0553, -0.0512, -0.0464, -0.0409,\n",
      "         -0.0349, -0.0282, -0.0208, -0.0129, -0.0043,  0.0049,  0.0148,  0.0253,\n",
      "          0.0364,  0.0482]], device='cuda:0')\n",
      "LOSS tensor(0.7174, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder.cuda()\n",
    "rel_rec = rel_rec.cuda()\n",
    "rel_send = rel_send.cuda()\n",
    "from utils import *\n",
    "\n",
    "for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "    if batch_idx<10:\n",
    "        data, relations = data.cuda(), relations.cuda()\n",
    "        output, logits, all_msgs, msg = decoder(data, rel_rec, rel_send,\n",
    "                                 0.5, True, 1)\n",
    "#         print(output.size(), msg.size())\n",
    "#         print(msg[0,0,48], all_msgs[0,0,48])\n",
    "        print('jjjj',batch_idx, output[0,-2:,:,0], '\\n',data[0,-2:,1:,0])\n",
    "        target = data[:, :, 1:, :] \n",
    "        loss_nll = nll_gaussian(output, target, 5e-5)\n",
    "        print('LOSS', loss_nll)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6803, 0.3197],\n",
       "          [0.6883, 0.3117],\n",
       "          [0.6914, 0.3086],\n",
       "          [0.6982, 0.3018],\n",
       "          [0.6948, 0.3052],\n",
       "          [0.6890, 0.3110],\n",
       "          [0.6933, 0.3067],\n",
       "          [0.6903, 0.3097],\n",
       "          [0.6831, 0.3169],\n",
       "          [0.6981, 0.3019],\n",
       "          [0.6968, 0.3032],\n",
       "          [0.6921, 0.3079],\n",
       "          [0.6971, 0.3029],\n",
       "          [0.6995, 0.3005],\n",
       "          [0.6928, 0.3072],\n",
       "          [0.6887, 0.3113],\n",
       "          [0.6826, 0.3174],\n",
       "          [0.6694, 0.3306],\n",
       "          [0.6728, 0.3272],\n",
       "          [0.6957, 0.3043],\n",
       "          [0.6897, 0.3103],\n",
       "          [0.6852, 0.3148],\n",
       "          [0.6906, 0.3094],\n",
       "          [0.6727, 0.3273],\n",
       "          [0.6871, 0.3129],\n",
       "          [0.6751, 0.3249],\n",
       "          [0.6903, 0.3097],\n",
       "          [0.6907, 0.3093],\n",
       "          [0.6980, 0.3020],\n",
       "          [0.6975, 0.3025],\n",
       "          [0.6998, 0.3002],\n",
       "          [0.6941, 0.3059],\n",
       "          [0.6981, 0.3019],\n",
       "          [0.6991, 0.3009],\n",
       "          [0.6964, 0.3036],\n",
       "          [0.6700, 0.3300],\n",
       "          [0.6641, 0.3359],\n",
       "          [0.2195, 0.7805],\n",
       "          [0.1943, 0.8057],\n",
       "          [0.6682, 0.3318],\n",
       "          [0.6768, 0.3232],\n",
       "          [0.3933, 0.6067],\n",
       "          [0.5633, 0.4367],\n",
       "          [0.5262, 0.4738],\n",
       "          [0.4615, 0.5385],\n",
       "          [0.4042, 0.5958],\n",
       "          [0.5167, 0.4833],\n",
       "          [0.2426, 0.7574],\n",
       "          [0.3736, 0.6264]]]], device='cuda:0')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = decoder.rel_graph.softmax(-1)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 1, 1, 56, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 3, 4, 5]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[3,4,5]])\n",
    "a.reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "f = np.load('data/edges_train_my.npy')\n",
    "print(f.shape)\n",
    "# for i in range(100):\n",
    "#     print(f[i,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6996, 0.3004],\n",
       "        [0.6988, 0.3012],\n",
       "        [0.6934, 0.3066],\n",
       "        [0.7002, 0.2998],\n",
       "        [0.6991, 0.3009],\n",
       "        [0.6969, 0.3031],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6993, 0.3007],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6994, 0.3006],\n",
       "        [0.7002, 0.2998],\n",
       "        [0.6990, 0.3010],\n",
       "        [0.7005, 0.2995],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6982, 0.3018],\n",
       "        [0.6867, 0.3133],\n",
       "        [0.6986, 0.3014],\n",
       "        [0.6967, 0.3033],\n",
       "        [0.6998, 0.3002],\n",
       "        [0.6982, 0.3018],\n",
       "        [0.6973, 0.3027],\n",
       "        [0.6989, 0.3011],\n",
       "        [0.6933, 0.3067],\n",
       "        [0.6990, 0.3010],\n",
       "        [0.6935, 0.3065],\n",
       "        [0.6974, 0.3026],\n",
       "        [0.6959, 0.3041],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.6996, 0.3004],\n",
       "        [0.6969, 0.3031],\n",
       "        [0.6991, 0.3009],\n",
       "        [0.6995, 0.3005],\n",
       "        [0.6985, 0.3015],\n",
       "        [0.6975, 0.3025],\n",
       "        [0.6360, 0.3640],\n",
       "        [0.6223, 0.3777],\n",
       "        [0.4439, 0.5561],\n",
       "        [0.4107, 0.5893],\n",
       "        [0.6092, 0.3908],\n",
       "        [0.5939, 0.4061],\n",
       "        [0.5542, 0.4458],\n",
       "        [0.5935, 0.4065],\n",
       "        [0.5791, 0.4209],\n",
       "        [0.5709, 0.4291],\n",
       "        [0.4844, 0.5156],\n",
       "        [0.5939, 0.4061],\n",
       "        [0.4927, 0.5073],\n",
       "        [0.5772, 0.4228]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[s,c,friction,t,m,vel,loc]\n",
    "torch.Tensor(np.squeeze(np.load('logs/exp2020-06-30T21:28:03.944345/130_rel_graph.npy'))[0]).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self loop, one_hot\n",
    "#not self loop, one_hot; not self loop, no one_hot -> velocity all zeros??\n",
    "#if all zeros, should predict vel=0\n",
    "\n",
    "#tau=0.5; kl smaller; roll out predict step more\n",
    "#study influnce of delta theta and mu\n",
    "#[s,c,friction,t,m,vel,loc]\n",
    "#generate more toy data\n",
    "\n",
    "#toy 4\n",
    "torch.Tensor(np.load('logs/exp2020-07-04T21:07:44.112351/190_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 3\n",
    "torch.Tensor(np.load('logs/exp2020-07-04T21:13:41.574115/160_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 6\n",
    "torch.Tensor(np.load('logs/exp2020-07-04T21:15:17.252488/160_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7002, 0.2998],\n",
       "         [0.7019, 0.2981],\n",
       "         [0.6978, 0.3022],\n",
       "         [0.7049, 0.2951],\n",
       "         [0.7011, 0.2989],\n",
       "         [0.7007, 0.2993],\n",
       "         [0.7004, 0.2996]],\n",
       "\n",
       "        [[0.7021, 0.2979],\n",
       "         [0.6992, 0.3008],\n",
       "         [0.6840, 0.3160],\n",
       "         [0.7051, 0.2949],\n",
       "         [0.7008, 0.2992],\n",
       "         [0.7006, 0.2994],\n",
       "         [0.7009, 0.2991]],\n",
       "\n",
       "        [[0.7006, 0.2994],\n",
       "         [0.6989, 0.3011],\n",
       "         [0.6951, 0.3049],\n",
       "         [0.6171, 0.3829],\n",
       "         [0.6938, 0.3062],\n",
       "         [0.6979, 0.3021],\n",
       "         [0.6971, 0.3029]],\n",
       "\n",
       "        [[0.7018, 0.2982],\n",
       "         [0.7008, 0.2992],\n",
       "         [0.6872, 0.3128],\n",
       "         [0.6997, 0.3003],\n",
       "         [0.6990, 0.3010],\n",
       "         [0.6998, 0.3002],\n",
       "         [0.6996, 0.3004]],\n",
       "\n",
       "        [[0.7017, 0.2983],\n",
       "         [0.7020, 0.2980],\n",
       "         [0.6818, 0.3182],\n",
       "         [0.7018, 0.2982],\n",
       "         [0.7007, 0.2993],\n",
       "         [0.7005, 0.2995],\n",
       "         [0.7002, 0.2998]],\n",
       "\n",
       "        [[0.6974, 0.3026],\n",
       "         [0.6866, 0.3134],\n",
       "         [0.1632, 0.8368],\n",
       "         [0.2019, 0.7981],\n",
       "         [0.6865, 0.3135],\n",
       "         [0.6078, 0.3922],\n",
       "         [0.4130, 0.5870]],\n",
       "\n",
       "        [[0.6413, 0.3587],\n",
       "         [0.6552, 0.3448],\n",
       "         [0.3718, 0.6282],\n",
       "         [0.4023, 0.5977],\n",
       "         [0.6431, 0.3569],\n",
       "         [0.2107, 0.7893],\n",
       "         [0.5470, 0.4530]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sparsity increase, set to 0 and compare loss (find loss lower bound)\n",
    "torch.Tensor(np.load('logs/exp2020-07-02T22:38:52.295235/490_rel_graph.npy')[-1]).argmax(-1).view(7,7)#softmax(-1).view(7,7,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 2: prdicts b out with high prob but <0.01 for a\n",
    "torch.Tensor(np.load('logs/exp2020-07-07T04:13:10.396214/140_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/exp2020-07-07T04:20:24.869651/`60_rel_graph.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d0a21ce326ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/exp2020-07-07T04:20:24.869651/`60_rel_graph.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/cmr/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/exp2020-07-07T04:20:24.869651/`60_rel_graph.npy'"
     ]
    }
   ],
   "source": [
    "#toy 7\n",
    "import torch\n",
    "import numpy as np\n",
    "torch.Tensor(np.load('logs/exp2020-07-07T04:20:24.869651/`60_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/exp2020-07-07T04:15:46.169058/240_rel_graph.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d6e14c42c0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#toy 5: training for many vars prob to decrease\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/exp2020-07-07T04:15:46.169058/240_rel_graph.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/cmr/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/exp2020-07-07T04:15:46.169058/240_rel_graph.npy'"
     ]
    }
   ],
   "source": [
    "#toy 5: training for many vars prob to decrease\n",
    "torch.Tensor(np.load('logs/exp2020-07-07T04:15:46.169058/240_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3]\n",
    "x[0::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 1\n",
    "torch.Tensor(np.load('logs/exp2020-07-04T21:10:35.626412/180_rel_graph.npy')[-1]).argmax(-1).view(7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 1\n",
    "torch.Tensor(np.load('logs/exp2020-07-03T02:00:19.133317/660_rel_graph.npy')[-1]).argmax(-1).view(7,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([decoder.state_dict(), rel_w],'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.        ,   17.72001552,   70.88006207,  159.48013966,\n",
       "         283.52024829,  443.00038795,  637.92055865,  868.28076039,\n",
       "        1134.08099316, 1435.32125697, 1772.00155181, 2144.12187769,\n",
       "        2551.68223461, 2994.68262256, 3473.12304155, 3987.00349158,\n",
       "        4536.32397264, 5121.08448474, 5741.28502787]),\n",
       " array([0.00000000e+00, 7.08800621e+01, 6.37920559e+02, 2.55168223e+03,\n",
       "        7.08800621e+03, 1.59480140e+04, 3.12581074e+04, 5.55699687e+04,\n",
       "        9.18605604e+04, 1.43532126e+05, 2.14412188e+05, 3.08753550e+05,\n",
       "        4.31234298e+05, 5.86957794e+05, 7.81452684e+05, 1.02067289e+06,\n",
       "        1.31099763e+06, 1.65923137e+06, 2.07260390e+06]))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step=19\n",
    "u0=0\n",
    "v0=0\n",
    "g=9.8\n",
    "mus=[0.001, 0.05, 0.1, 0.5, 0.98]\n",
    "mu=mus[4]\n",
    "thetas= [math.pi/90, math.pi/6,math.pi/4,math.pi/3,math.pi*44/45]\n",
    "interval=2\n",
    "\n",
    "\n",
    "L_vars=[]\n",
    "V_vars=[]\n",
    "\n",
    "for mu in mus:\n",
    "    L=[]\n",
    "    V=[]\n",
    "    for theta in thetas:\n",
    "        loc = np.zeros(step)\n",
    "        loc[0] = u0\n",
    "        vel = np.zeros(step)\n",
    "        vel[0] = v0\n",
    "        for i in range(1, step):\n",
    "            loc[i]=loc[i-1]+vel[i-1]*interval+0.5*g*(np.sin(theta)-np.cos(theta)*mu)*(interval**2)\n",
    "            vel[i] = vel[i-1]+g*(np.sin(theta)-np.cos(theta)*mu)\n",
    "        V.append(vel)\n",
    "        L.append(loc)\n",
    "    V=np.array(V)    \n",
    "    L=np.array(L)  \n",
    "    V_vars.append(V.var(0))\n",
    "    L_vars.append(L.var(0))\n",
    "\n",
    "np.array(V_vars).mean(0), np.array(L_vars).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.load('logs/exp2020-07-11T17:10:45.016169/180_rel_graph.npy')[-1]).argmax(-1).view(8,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#sin cos\n",
    "torch.Tensor(np.load('logs/exp2020-07-14T13:55:08.770691/560_rel_graph.npy')[-1]).argmax(-1).view(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.load('logs/exp2020-07-16T19:00:03.362900/10_rel_graph.npy')[-1]).argmax(-1).view(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHO\n",
    "torch.Tensor(np.load('logs/exp2020-07-14T22:09:52.789567/690_rel_graph.npy')[-1]).argmax(-1).view(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#toy 9\n",
    "torch.Tensor(np.load('logs/exp2020-07-14T18:35:30.572260/560_rel_graph.npy')[-1]).argmax(-1).view(17,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gravity\n",
    "torch.Tensor(np.load('logs/exp2020-07-14T22:24:59.531529/500_rel_graph.npy')[-1]).argmax(-1).view(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6685, 0.3315],\n",
       "         [0.6875, 0.3125],\n",
       "         [0.6166, 0.3834],\n",
       "         [0.6898, 0.3102],\n",
       "         [0.7279, 0.2721],\n",
       "         [0.6833, 0.3167],\n",
       "         [0.6977, 0.3023],\n",
       "         [0.6461, 0.3539],\n",
       "         [0.6808, 0.3192]],\n",
       "\n",
       "        [[0.7337, 0.2663],\n",
       "         [0.7290, 0.2710],\n",
       "         [0.6590, 0.3410],\n",
       "         [0.7243, 0.2757],\n",
       "         [0.7520, 0.2480],\n",
       "         [0.7433, 0.2567],\n",
       "         [0.7043, 0.2957],\n",
       "         [0.6922, 0.3078],\n",
       "         [0.7330, 0.2670]],\n",
       "\n",
       "        [[0.6587, 0.3413],\n",
       "         [0.7299, 0.2701],\n",
       "         [0.7225, 0.2775],\n",
       "         [0.7125, 0.2875],\n",
       "         [0.7357, 0.2643],\n",
       "         [0.6903, 0.3097],\n",
       "         [0.7166, 0.2834],\n",
       "         [0.6636, 0.3364],\n",
       "         [0.7214, 0.2786]],\n",
       "\n",
       "        [[0.7351, 0.2649],\n",
       "         [0.7070, 0.2930],\n",
       "         [0.7008, 0.2992],\n",
       "         [0.7309, 0.2691],\n",
       "         [0.7159, 0.2841],\n",
       "         [0.7526, 0.2474],\n",
       "         [0.7357, 0.2643],\n",
       "         [0.7066, 0.2934],\n",
       "         [0.7098, 0.2902]],\n",
       "\n",
       "        [[0.6670, 0.3330],\n",
       "         [0.6814, 0.3186],\n",
       "         [0.6517, 0.3483],\n",
       "         [0.6921, 0.3079],\n",
       "         [0.6950, 0.3050],\n",
       "         [0.7267, 0.2733],\n",
       "         [0.7055, 0.2945],\n",
       "         [0.7006, 0.2994],\n",
       "         [0.7662, 0.2338]],\n",
       "\n",
       "        [[0.6620, 0.3380],\n",
       "         [0.6626, 0.3374],\n",
       "         [0.2532, 0.7468],\n",
       "         [0.4558, 0.5442],\n",
       "         [0.7050, 0.2950],\n",
       "         [0.6457, 0.3543],\n",
       "         [0.4349, 0.5651],\n",
       "         [0.6228, 0.3772],\n",
       "         [0.3738, 0.6262]],\n",
       "\n",
       "        [[0.6568, 0.3432],\n",
       "         [0.6886, 0.3114],\n",
       "         [0.2668, 0.7332],\n",
       "         [0.4418, 0.5582],\n",
       "         [0.6567, 0.3433],\n",
       "         [0.3593, 0.6407],\n",
       "         [0.6651, 0.3349],\n",
       "         [0.6288, 0.3712],\n",
       "         [0.4197, 0.5803]],\n",
       "\n",
       "        [[0.7133, 0.2867],\n",
       "         [0.7042, 0.2958],\n",
       "         [0.6777, 0.3223],\n",
       "         [0.7360, 0.2640],\n",
       "         [0.6585, 0.3415],\n",
       "         [0.7487, 0.2513],\n",
       "         [0.7224, 0.2776],\n",
       "         [0.6964, 0.3036],\n",
       "         [0.7603, 0.2397]],\n",
       "\n",
       "        [[0.6346, 0.3654],\n",
       "         [0.6935, 0.3065],\n",
       "         [0.7071, 0.2929],\n",
       "         [0.6860, 0.3140],\n",
       "         [0.6465, 0.3535],\n",
       "         [0.7484, 0.2516],\n",
       "         [0.7358, 0.2642],\n",
       "         [0.7073, 0.2927],\n",
       "         [0.6917, 0.3083]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.load('logs/exp2020-07-16T19:02:57.867514/300_rel_graph.npy')[-1]).softmax(-1).view(9,9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
